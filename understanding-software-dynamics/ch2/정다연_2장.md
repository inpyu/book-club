# CH2

# 과거에서 지금까지의 발자취

- 1950년대
    - CPU 클럭 사이클 - 코어 메모리 사이클이 동일 ⇒ 명령어 완료 시 두 사이클만 걸리게 된다.
        - 첫 사이클 → 명령어 패치, 메모리로 명령어 해석
        - 두번째 사이클 → 데이터에 접근해 명령어 실행
    - 이후 홀/짝으로 명령어를 가져와 첫 명령어 실행ㅅ ㅣ두번째는 임시 명령어 레지스터에 보관
- 둘 이상의 코어 메모리 유닛 → 다른 메모리 유닛 접근 시 N의 실행과 동시에 N+1을 가져오는 것
- 트랜지스터의 출현 → CPU 시간 개선, But 코어 메모리 접근 시간은 개선 X
    - 처리속도를 높이기 위해 CPU와 메모리 클럭 분리 , 각각의 메모리 참조에 여러 CPU 사이클 사용
    - CPU 내부의 다양한 레지스터 사용 → 쓰기가 끝나는 마지막 CPU 클럭까지 기다리지 않고 레지스터간 데이터 접근 가능.
- CDC 6600
    - 다중 파이프라인 실행 유닛 → 순서없이 완료될 수 있는 명령어 병렬 실행
    - 최대 4개의 명령어를 60비트의 단일 워드 압축
    - 8개의 데이터 레지스터, 8개의 주소 레지스터 O
    - 내부에 작은 루프를 저장할 수 있는 루프 버퍼 보유 → 반복 이후 명령어 패치 불필요
- 맨체스터 아틀라스
    - 페이징된 가상 메모리를 탑재한 최초의 사용ㅇ 장비
    - 16K의 물리적인 메인 메모리를 96K의 가상 메모리로 사용 → 속도는 느려도 큰 메모리처럼 사용 가능
    - 페이지가 필요할 때 마다 메인 메모리와 드럼 메모리 사이를 이동 가능
- System/370
    - 1972년 가상 메모리를 추가해 기능을 활성화해 출시
    - 메모리 접근마다 가상주소를 물리주소로 변환하는 TLB 사용 → 초기 CPU 사이클타임이 느려도, 대용량 데이터가 있는 대형 프로그램이 메인메모리와 백업디스크, 드럼 간 데이터 주고받는 기술을 빠르게[ 사용 가능
    - 주소 맵핑 → 페이지 단위로 메모리 보호 가능
        - 하나의 시스템 실행 → 서로간 메모리 접근 보호
        - 사용자 모드 → 커널 모드 페이지를 건드리지 못하도록 보호 가능
        - 보호 비트 → 개별 페이지 쓰기 금지, 실행 금지 설정 → 보안 강화
- ASC -1
    - 클럭 사이클마다 둘 이상의 명령어 사용 → 명령어 처리 속도의 장벽을 허묾
    - 두 명령어가 끝나기 전에 명령어를 실행한 뒤 다음 명령어를 시작하는 파이프라인 설계
    - 최대 7개의 명령어 수행 가능
- IBM 360/85
    - 1968년 코어 메인 메모리 접근시간 속도 비율이 13:1인 캐시 메모리 도입 → 오늘날은 약 200:1
    - 메인 메모리를 보조하는 단일 레벨의 캐시 탑재
- 오늘날의 마이크로프로세서 칩
    - 다차원의 내부 캐시 칩 → cPU 코어 하나 당 작지만 빠른 L1 캐시 존재
    - 단일 코어의 성능이 평준화 → 다중 CPU 코어 도입
    - 멀티 스레딩 기술의 도입

# 지금의 위치

현대 프로세서는 아래 속도 향상 기술을 모두 사용한다

- CPU와 메모리 클럭의 의존성 분리
- 다중 메모리 뱅크
- 다중 데이터 레지스터
- 워드당 다중 명령어
- 명령어 파이프라이닝
- 다중 실행 유닛
- 에측 실행
- 다중 명령어 발행
- 무작위 실행
- 캐시 메모리
- 페이징된 가상 메모리
- 동시 멀티스레딩

# add 명령어의 지연시간 측정

- 명령어 지연시간 → 실행부터 결과를 사용하는 후속 명령어의 첫번째 실행까지의 CPU 사이클
    
    - ex) B가 add 명령, C가 기다리지 않고 합한 결과 사용
        - C의 실행 사이클 → B의 실행 보다 한사이클 뒤에 실행됨.
        - B의 실행 지연 시간 → 한사이클
        - C의 실행 사이클 → B의 쓰기 사이클과 겹침
    - 느린 하드웨어 → 레지스터에서 C의 읽기를 시작 전 B의 쓰기가 완료되도록 요청하므로 한두사이클이 느려짐
- 분기 명령어의 지연시간 → 명령어 패치부터 다음 명령어 패치까지의 CPU 사이클을 의미
    - 명령어 패치, 해석, 분기단계에서의 여러 사이클이 걸리면 분기 지연시간으로 나타날 수 있음.
    
    ⇒ 하드웨어로 분기 이후를 정확히 예측하여 지연시간을 줄일 수 있다.
    

**Add 명령어 지연시간 측정 방법**

1. 시간 읽기
    1. add 명령어 실행
2. 시간 읽기
3. 두 시간의 차이 빼기

- 시간 읽기 → add 명령어에 대한 한 사이클의 차이도 계산할 수 있는 정확한 CPU 사이클을 계산
    - 일부 컴퓨터 → 사이클마다 하나씩 증가하는 사이클 카운터 존재
    - 사이클을 계산하지 않고 경과 시간만 계산 가능
    
    ⇒ 해당 방법은 한동안 일정했으나, CPU 클럭을 동적으로 느리게 만든느 절전 기술의 등장으로 절전 여부에 따라 실제 시간과 큰 차이가 있음을 알게됨. 
    
- 의미 있는 결과 도출 → RDTSC 명령어 사이에서 수천~수만 사이클의 작업을 수행하고, cPU가 절전상태가 아닐때 작업을 수행해야 한다.
    - 각 읽기마다 10nsec정도의 오차 발생 가능 → 1% 미만으로 유지하려면, 읽기 사이 작업량이 최소 1000nsec이거나, 2.4GHz에서는 2400사이클이 되어야 한다.

⇒ 즉 , 수천개를 묶어서 한번에 측정하는 편이 좋다. add 명령어를 N번 실행하고, N을 나누는 방식으로 채택을 ..?

- 해당 방법 → 하나의 add 명령어 지연시간과 차이가 있을 수 있다.

# 직선형 코드의 실수

```yaml
sum += 1
sum += 1
sum += 1
sum += 1
sum += 1
...
```

반복문 없이 5000줄의 코드 → add 명령어를 측정하는 것이 아니라, 1000개 이상의 순차적 명령어를 패치하는 비율이나, 1단계 데이터 캐시에서 합계 데이터를 불러오거나 저장하는데 걸리는 코드를 측정하는 것과 같다.

# 간단한 반복문, 반복문 오버헤드 실수, 컴파일러 최적화

```c
start = RDTSC();
for (int n=0; n<5000; n++){
	sum += 1;
}
delta = RDTSC() - start;
```

위와 같이 반복문을 수행한 뒤 5000으로 나누는 경우

→ add 명령어를 단일로 사용할 때보다 반복문 내부의 증가, 비교, 조건의 분기를 수행하게 된다. 해당 for문이 들어간 것을 최적화하여 순수한 시간을 측정해야 한다.

- gcc 옵티마이저는 효율적으로 처리하기 위해 1의 10억 제곱을 미리 계산된 10억을 상수로 저장한 뒤, rdtsc 명령어 사이의 시간을 측정하는 방식으로 가능하다.

```c
// Sample mystery program to measure how long an add takes. Flawed.
// Copyright 2021 Richard L. Sites

#include <stdint.h>
#include <stdio.h>
#include <time.h>
#include "timecounters.h"

static const int kIterations = 1000 * 1000000;

int main (int argc, const char** argv) {
  uint64_t sum = 0;

  int64_t startcy = GetCycles();
  for (int i = 0; i < kIterations; ++i) {
    sum += 1;
  }
  int64_t elapsed = GetCycles() - startcy;
	
  double felapsed = elapsed;
  fprintf(stdout, "%d iterations, %lu cycles, %4.2f cycles/iteration\n", 
          kIterations, elapsed, felapsed / kIterations);
  return 0;
}

```

사이클의 카운트를 읽을수 있도록 gcc 컴파일러의 내장된 __rdtsc()를 사용한다.


# 사용되지 않는 변수로 인한 실패

옵티마이즈의 무력화 → 컴파일러가 모르는 상수를 사용해야 한다.

- 표준 컴파일러 최적화 → 프로그램의 다른 곳에서 사용되지 않는 계산식을 포함한 코드 제거
    - sum 변수가 사용되지 않으므로, 계산에 관여하는 모든 것을 최적화 한 뒤 포함된 반복문을 비우게 된다.
    
    ⇒ 효과가 없는 코드를 삭제해 전체 반복문을 제거
    
    - 컴파일러의 반복문 보존 → sum 변수를 출력하는 등 의도적으로 변수를 살아있게 한다.

# 향상된 반복문

- sum이나 increment 변수를 volatile로 선언해 전체 반복문을 수행하도록 컴파일에 강제화 가능
    - volatile 변수는 다른 코드가 공유된 메모리에 접근 가능 → 언제든 변경 가능하다.
    - 컴파일러 → 상수를 분석해 최적화 하는 것이 가닌 항상 공유 메모리의 값을 직접 읽고 쓰게 된다.
    
    ⇒ 오버헤드 문제 해결은 불가능하지만, 반복문을 그대로 유지 가능
    
- 반복문의 내용을 평문으로 작성하고, 반복문을 풀면 오버헤드가 감소
    - 두개의 반복문 시간 측정 후 차이 비교 → 오버헤드 시간 제거 가능

# 의존적인 변수

```c
for(int i=0; i<kIterations; i+=4){
	sum +=1;
	sum2 +=1;
	sum +=1;
	sum2 +=1;
}
```

- sum 변수만 사용하는 것이 아닌 sum, sum2 변수의 사용
    - add 명령어가 10억개는 5억 사이클이 걸리고, add 명령어는 0.5 사이클 정도 된다.

# 실제 실행 지연시간

실행시간 대신 지연시간 측정 → 이전의 명령어의 결과에 의존하는지 확인

컴파일러는 정수와 더하기와 곱하기와 같은 연산자에 대한 재졍렬 연산을 하기도 한다.

# 몇가지 추가 차이점

다시 연산을 피하기 → gcc -fno-tree-reassoc 플래그의 사용